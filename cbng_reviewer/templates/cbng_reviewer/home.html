{% extends "cbng_reviewer/base.html" %}
{% load django_bootstrap5 %}
{% block title %}ClueBot NG Review Interface{% endblock title %}
{% block content %}
    <div class="container">
        <div class="row">
            <div class="col-4 text-center">
                <p>Here are some stats:</p>
                <table class="table table-borderless">
                    <tr>
                        <th scope="col">Nickname</th>
                        <th scope="col">Contributions</th>
                    </tr>
                    {% for username, edits in user_statistics %}
                        <tr>
                            <td>{{ username }}</td>
                            <td>{{ edits }}</td>
                        </tr>
                    {% endfor %}
                </table>
            </div>
            <div class="col-8">
                {% if user.is_reviewer %}
                    <p>
                        In the review interface, you will have a browser window with Wikipedia articles, and a window sitting on
                        top
                        where you can classify edits.
                        You will be able to click links and such in the main browser window without interrupting the process.
                        The window sitting on top allows you to classify edits as Vandalism, Constructive, or Skip.
                    </p>
                    <p>
                        In general, if an edit would be classified as vandalism by a human, it should be classified as
                        vandalism.
                        Most other edits should be classified as constructive, with a few exceptions (and because many of the
                        edits
                        in the review queue may be borderline, you may encounter these exceptions more often than you might
                        think).
                        Skipping an edit excludes it from the dataset entirely.
                        An edit may be skipped if it's borderline vandalism, and it's not a big deal if the bot classifies edits
                        like it as vandalism in production.
                        An edit may also be skipped if you can"t tell whether or not it's vandalism.
                        The other case where skipping edits may be acceptable is if the edit is not vandalism,
                        but is a very poor quality edit, and contains some attributes of vandalism.
                        Although very poor edits made in good faith technically should not be classified as vandalism,
                        classifying them as constructive could interfere with the bot"s training, so they should be skipped.
                    </p>
                    <p>
                        In some cases, the interface may ask "Are you sure?" when you select a result.
                        If this happens, double-check that your classification is correct, then click Yes or No.
                    </p>
                    <p>
                        There is also a Comment box along with the Vandalism, Constructive, and Skip buttons.
                        This is optional.
                        If you think there"s something about the edit that the Cluebot-NG operators should know about,
                        such as an edit that"s clearly constructive but may look like vandalism based on simple statistics,
                        leave a comment about it, and the Cluebot-NG operators will take that into account.
                    </p>
                    <p>
                        To be clear, if an edit is definitely vandalism, even if it's not easy-to-catch vandalism, still mark it
                        as
                        vandalism!
                        The bot is capable of catching many things you may not think it can - do not baby the bot!
                        If it's vandalism, mark it as such!
                    </p>
                    {% if admin_only_mode %}
                    <p>
                        The system is currently in admin mode, this is usually done for maintenance.
                        Please return later to access the review interface.
                    </p>
                    {% endif %}
                    {% if not admin_only_mode or user.is_admin %}
                    <p>
                        To get started, <a href="{% url 'review' %}">click here</a>.
                    </p>
                    {% endif %}
                {% elif user.is_authenticated %}
                    <p>
                        Your account (<a href="https://en.wikipedia.org/wiki/User:{{ user.username }}">{{ user.username }}</a>)
                        is pending approval by one of the administrators.
                    </p>
                    <p>If you would like to discuss your account, please reach out to one of the administrators:</p>
                    <ul>
                        {% for administrator in administrators %}
                            <li>
                                <a href="https://en.wikipedia.org/wiki/User_talk:{{ administrator }}">{{ administrator }}</a>
                            </li>
                        {% endfor %}
                    </ul>
                {% else %}
                    <p>
                        One of the keys to Cluebot NG functioning well is its dataset.
                        The larger and more accurate its dataset it, the better it will function, with fewer false positives,
                        and
                        more caught vandalism.
                        It's impossible for just a few people to manually review the thousands of edits necessary, so Cobi wrote
                        a
                        dataset review interface to allow people to review edits and classify them as vandalism or constructive.
                    </p>
                    <p>
                        This interface is used for a few things.
                        Firstly, it's used to make sure the dataset we already have is accurate.
                        False positives and false negatives from the trial dataset are put in the review queue, because we've
                        found
                        that a very few edits in the dataset may not be correctly classified.
                        This causes problems in the bot"s training and threshold calculations.
                    </p>
                    <p>
                        Also, random edits from Wikipedia may be added to the review queue to grow the overall size of the
                        dataset.
                    </p>
                    <p>
                        Classifying edits in this review interface can actually help Wikipedia more with your time than just
                        hunting
                        vandalism.
                        Hunting vandalism manually may catch a small fraction of a percent of vandalism on Wikipedia.
                        Classifying edits in this interface may allow Cluebot-NG to catch 5% or more of additional vandalism.
                    </p>
                    <p>
                        To begin, you need to <a href="{% url 'social:begin' 'mediawiki' %}">log in</a>.
                    </p>
                {% endif %}
            </div>
        </div>
    </div>
{% endblock content %}
